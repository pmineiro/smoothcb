{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b84a1d",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b279b8",
   "metadata": {
    "code_folding": [
     2,
     31,
     45,
     63,
     81,
     109,
     126
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class EasyAcc:\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "        self.sum = 0\n",
    "        self.sumsq = 0\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "        self.n += 1\n",
    "        self.sum += other\n",
    "        self.sumsq += other*other\n",
    "        return self\n",
    "\n",
    "    def __isub__(self, other):\n",
    "        self.n += 1\n",
    "        self.sum -= other\n",
    "        self.sumsq += other*other\n",
    "        return self\n",
    "\n",
    "    def mean(self):\n",
    "        return self.sum / max(self.n, 1)\n",
    "\n",
    "    def var(self):\n",
    "        from math import sqrt\n",
    "        return sqrt(self.sumsq / max(self.n, 1) - self.mean()**2)\n",
    "\n",
    "    def semean(self):\n",
    "        from math import sqrt\n",
    "        return self.var() / sqrt(max(self.n, 1))\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        import numpy\n",
    "        \n",
    "        self.data = numpy.load('652_contest.npy')\n",
    "        self.ys = torch.Tensor(self.data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 10**5\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Select sample\n",
    "        generator = torch.Generator().manual_seed(index)\n",
    "        realized = torch.bernoulli(input=self.ys, generator=generator)\n",
    "        return realized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f6a4ca2",
   "metadata": {
    "code_folding": [
     0,
     35
    ]
   },
   "outputs": [],
   "source": [
    "class CountTable(object):\n",
    "    def __init__(self, naction):\n",
    "        self.table = [ [0, 0, 0.0] for _ in range(naction) ]\n",
    "        \n",
    "    def fhat(self):\n",
    "        return torch.Tensor([ x[2] for x in self.table ])\n",
    "        \n",
    "    def update(self, action, reward):\n",
    "        for a, r in map(lambda x: (x[0].item(), x[1].item()), zip(action, reward)):\n",
    "            self.table[a][1] += 1\n",
    "            self.table[a][0] += r\n",
    "            self.table[a][2] = self.table[a][0] / self.table[a][1]\n",
    "\n",
    "class CorralIGW(object):\n",
    "    def __init__(self, *, eta, gammamin, gammamax, nalgos, device):\n",
    "        import numpy\n",
    "        \n",
    "        super(CorralIGW, self).__init__()\n",
    "        \n",
    "        self.eta = eta / nalgos\n",
    "        self.gammas = torch.Tensor(numpy.geomspace(gammamin, gammamax, nalgos), device=device)\n",
    "        self.invpalgo = torch.Tensor([ self.gammas.shape[0] ] * self.gammas.shape[0], device=device)\n",
    "        \n",
    "    def update(self, algo, invprop, reward):\n",
    "        import numpy\n",
    "        from scipy import optimize\n",
    "        \n",
    "        assert torch.all(reward >= 0) and torch.all(reward <= 1), reward\n",
    "        \n",
    "        weightedlosses = self.eta * (-reward.squeeze(1)) * invprop.squeeze(1)\n",
    "        newinvpalgo = torch.scatter(input=self.invpalgo,\n",
    "                                    dim=0,\n",
    "                                    index=algo,\n",
    "                                    src=weightedlosses,\n",
    "                                    reduce='add')\n",
    "                                    \n",
    "        # just do this calc on the cpu\n",
    "        invp = newinvpalgo.cpu().numpy() \n",
    "        invp += 1 - numpy.min(invp)\n",
    "        Zlb = 0\n",
    "        Zub = 1\n",
    "        while (numpy.sum(1 / (invp + Zub)) > 1):\n",
    "            Zlb = Zub\n",
    "            Zub *= 2 \n",
    "        root, res = optimize.brentq(lambda z: 1 - numpy.sum(1 / (invp + z)), Zlb, Zub, full_output=True)\n",
    "        assert res.converged, res\n",
    "        \n",
    "        self.invpalgo = torch.Tensor(invp + root, device=self.invpalgo.device)\n",
    " \n",
    "    def sample(self, fhat):\n",
    "        N, K = fhat.shape\n",
    "\n",
    "        algosampler = torch.distributions.categorical.Categorical(probs=1.0/self.invpalgo, validate_args=False)\n",
    "        algo = algosampler.sample((N,))\n",
    "        invpalgo = torch.gather(input=self.invpalgo.unsqueeze(0).expand(N, -1),\n",
    "                                dim=1,\n",
    "                                index=algo.unsqueeze(1))\n",
    "        gamma = torch.gather(input=self.gammas.unsqueeze(0).expand(N, -1),\n",
    "                             dim=1,\n",
    "                             index=algo.unsqueeze(1))\n",
    "        \n",
    "        fhatstar, ahatstar = torch.max(fhat, dim=1, keepdim=True)\n",
    "        rando = torch.randint(high=K, size=(N, 1), device=fhat.device)\n",
    "        fhatrando = torch.gather(input=fhat, dim=1, index=rando)\n",
    "        probs = K / (K + gamma * (fhatstar - fhatrando))\n",
    "        unif = torch.rand(size=(N, 1), device=fhat.device)\n",
    "        shouldexplore = (unif <= probs).long()\n",
    "        return (ahatstar + shouldexplore * (rando - ahatstar)).squeeze(1), algo, invpalgo        \n",
    "\n",
    "def learnOnline(dataset, *, seed, eta, gammamin, gammamax, nalgos, batch_size):\n",
    "    import time\n",
    "    \n",
    "    trajectory = []\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    generator = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    log_loss = torch.nn.BCELoss()\n",
    "    model = None\n",
    "        \n",
    "    print('{:<5s}\\t{:<10s}\\t{:<10s}\\t{:<10s}\\t{:<10s}\\t{:<10s}\\t{:<10s}\\t{:<10s}'.format(\n",
    "            'n', 'loss', 'since last', 'acc', 'since last', 'reward', 'since last', 'dt (sec)'),\n",
    "          flush=True)\n",
    "    avloss, sincelast, acc, accsincelast, avreward, rewardsincelast = [ EasyAcc() for _ in range(6) ]\n",
    "    \n",
    "    for bno, ys in enumerate(generator):\n",
    "        if model is None:\n",
    "            import numpy as np\n",
    "            model = CountTable(naction=ys.shape[1])\n",
    "            sampler = CorralIGW(eta=eta, gammamin=gammamin, gammamax=gammamax, nalgos=nalgos, device=ys.device)\n",
    "            start = time.time()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            fhat = model.fhat().unsqueeze(0).expand(ys.shape[0], -1)\n",
    "            sample, algo, invpalgo = sampler.sample(fhat)\n",
    "            reward = torch.gather(input=ys, dim=1, index=sample.unsqueeze(1)).float()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            samplefhat = torch.gather(input=fhat, index=sample.unsqueeze(1), dim=1)\n",
    "            loss = log_loss(samplefhat, reward)\n",
    "            model.update(sample, reward.squeeze(1))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(fhat, dim=1)\n",
    "            ypred = torch.gather(input=ys, dim=1, index=pred.unsqueeze(1))\n",
    "            acc += torch.mean(ypred).float()\n",
    "            accsincelast += torch.mean(ypred).float()\n",
    "            avloss += loss\n",
    "            sincelast += loss\n",
    "            avreward += torch.mean(reward)\n",
    "            rewardsincelast += torch.mean(reward)\n",
    "            sampler.update(algo, invpalgo, reward)\n",
    "        \n",
    "        if bno & (bno - 1) == 0:\n",
    "            now = time.time()\n",
    "            print('{:<5d}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}'.format(\n",
    "                    avloss.n, avloss.mean(), sincelast.mean(), acc.mean(),\n",
    "                    accsincelast.mean(), avreward.mean(), rewardsincelast.mean(),\n",
    "                    now - start),\n",
    "                  flush=True)\n",
    "            trajectory.append((avloss.n, 1 - avreward.mean().item()))\n",
    "            sincelast, accsincelast, rewardsincelast = [ EasyAcc() for _ in range(3) ]\n",
    "            #print(f'sampler.palgo = { 1/sampler.invpalgo }')\n",
    "\n",
    "    now = time.time()\n",
    "    print('{:<5d}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}\\t{:<10.5f}'.format(\n",
    "            avloss.n, avloss.mean(), sincelast.mean(), acc.mean(),\n",
    "            accsincelast.mean(), avreward.mean(), rewardsincelast.mean(),\n",
    "            now - start),\n",
    "          flush=True)\n",
    "    trajectory.append((avloss.n, 1 - avreward.mean().item()))\n",
    "    #print(f'sampler.palgo = { 1/sampler.invpalgo }')\n",
    "    \n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd8789f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n    \tloss      \tsince last\tacc       \tsince last\treward    \tsince last\tdt (sec)  \n",
      "1    \t0.00000   \t0.00000   \t1.00000   \t1.00000   \t0.00000   \t0.00000   \t0.00691   \n",
      "2    \t0.00000   \t0.00000   \t1.00000   \t1.00000   \t0.00000   \t0.00000   \t0.01941   \n",
      "3    \t33.33333  \t100.00000 \t1.00000   \t1.00000   \t0.33333   \t1.00000   \t0.02731   \n",
      "5    \t40.00000  \t50.00000  \t0.60000   \t0.00000   \t0.20000   \t0.00000   \t0.03844   \n",
      "9    \t44.52146  \t50.17329  \t0.44444   \t0.25000   \t0.22222   \t0.25000   \t0.07238   \n",
      "17   \t58.96970  \t75.22397  \t0.41176   \t0.37500   \t0.41176   \t0.62500   \t0.15753   \n",
      "33   \t39.49024  \t18.79332  \t0.66667   \t0.93750   \t0.66667   \t0.93750   \t0.24698   \n",
      "65   \t30.88296  \t22.00671  \t0.72308   \t0.78125   \t0.63077   \t0.59375   \t0.43491   \n",
      "129  \t25.01378  \t19.05289  \t0.74419   \t0.76562   \t0.61240   \t0.59375   \t0.63657   \n",
      "257  \t22.81344  \t20.59592  \t0.73541   \t0.72656   \t0.62257   \t0.63281   \t0.86887   \n",
      "513  \t20.94362  \t19.06649  \t0.72710   \t0.71875   \t0.64133   \t0.66016   \t1.37877   \n",
      "1025 \t16.94183  \t12.93223  \t0.72585   \t0.72461   \t0.66537   \t0.68945   \t3.38596   \n",
      "2049 \t13.20488  \t9.46429   \t0.75891   \t0.79199   \t0.71010   \t0.75488   \t7.32281   \n",
      "4097 \t8.15899   \t3.11065   \t0.85892   \t0.95898   \t0.81962   \t0.92920   \t14.97842  \n",
      "8193 \t5.04455   \t1.92935   \t0.92945   \t1.00000   \t0.89503   \t0.97046   \t30.92170  \n",
      "16385\t3.18786   \t1.33094   \t0.96472   \t1.00000   \t0.93879   \t0.98254   \t64.56040  \n",
      "32769\t2.66275   \t2.13760   \t0.98236   \t1.00000   \t0.95709   \t0.97540   \t130.38428 \n",
      "65537\t2.35050   \t2.03825   \t0.99118   \t1.00000   \t0.96545   \t0.97382   \t256.41342 \n",
      "100000\t1.98936   \t1.30259   \t0.99422   \t1.00000   \t0.97133   \t0.98250   \t393.59314 \n"
     ]
    }
   ],
   "source": [
    "trajectory = learnOnline(MyDataset(), seed=4545, batch_size=1, eta=1, gammamin=1000, gammamax=1000000, nalgos=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8092a346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1, 1.0),\n",
       "  (2, 1.0),\n",
       "  (3, 0.6666666567325592),\n",
       "  (5, 0.7999999970197678),\n",
       "  (9, 0.7777777761220932),\n",
       "  (17, 0.5882352888584137),\n",
       "  (33, 0.3333333134651184),\n",
       "  (65, 0.3692307472229004),\n",
       "  (129, 0.38759690523147583),\n",
       "  (257, 0.3774319291114807),\n",
       "  (513, 0.35867446660995483),\n",
       "  (1025, 0.33463412523269653),\n",
       "  (2049, 0.28989750146865845),\n",
       "  (4097, 0.180375874042511),\n",
       "  (8193, 0.10496765375137329),\n",
       "  (16385, 0.06121450662612915),\n",
       "  (32769, 0.04290640354156494),\n",
       "  (65537, 0.03454536199569702),\n",
       "  (100000, 0.028670012950897217)],\n",
       " [(1, 1.0),\n",
       "  (2, 2.0),\n",
       "  (3, 1.9999999701976776),\n",
       "  (5, 3.999999985098839),\n",
       "  (9, 6.999999985098839),\n",
       "  (17, 9.999999910593033),\n",
       "  (33, 10.999999344348907),\n",
       "  (65, 23.999998569488525),\n",
       "  (129, 50.00000077486038),\n",
       "  (257, 97.00000578165054),\n",
       "  (513, 184.00000137090683),\n",
       "  (1025, 342.99997836351395),\n",
       "  (2049, 593.9999805092812),\n",
       "  (4097, 738.9999559521675),\n",
       "  (8193, 859.9999871850014),\n",
       "  (16385, 1002.9996910691261),\n",
       "  (32769, 1405.9999376535416),\n",
       "  (65537, 2263.9993891119957),\n",
       "  (100000, 2867.0012950897217)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory, [ (n, n*v) for n, v in trajectory ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c06763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - PyTorch",
   "language": "python",
   "name": "azureml_py38_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
